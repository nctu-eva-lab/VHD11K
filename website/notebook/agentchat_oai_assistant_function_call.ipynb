{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat with OpenAI Assistant using function call in AutoGen: OSS Insights for Advanced GitHub Data Analysis\n",
    "\n",
    "This Jupyter Notebook demonstrates how to leverage OSS Insight (Open Source Software Insight) for advanced GitHub data analysis by defining `Function calls` in AutoGen for the OpenAI Assistant. \n",
    "\n",
    "The notebook is structured into four main sections:\n",
    "\n",
    "1. Function Schema and Implementation\n",
    "2. Defining an OpenAI Assistant Agent in AutoGen\n",
    "3. Fetching GitHub Insight Data using Function Call\n",
    "\n",
    "### Requirements\n",
    "\n",
    "AutoGen requires `Python>=3.8`. To run this notebook example, please install:\n",
    "```bash\n",
    "pip install pyautogen\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "# %pip install \"pyautogen>=0.2.3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Schema and Implementation\n",
    "\n",
    "This section provides the function schema definition and their implementation details. These functions are tailored to fetch and process data from GitHub, utilizing OSS Insight's capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "from autogen import UserProxyAgent, config_list_from_json\n",
    "from autogen.agentchat.contrib.gpt_assistant_agent import GPTAssistantAgent\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.WARNING)\n",
    "\n",
    "ossinsight_api_schema = {\n",
    "    \"name\": \"ossinsight_data_api\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"question\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": (\n",
    "                    \"Enter your GitHub data question in the form of a clear and specific question to ensure the returned data is accurate and valuable. \"\n",
    "                    \"For optimal results, specify the desired format for the data table in your request.\"\n",
    "                ),\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"question\"],\n",
    "    },\n",
    "    \"description\": \"This is an API endpoint allowing users (analysts) to input question about GitHub in text format to retrieve the related and structured data.\",\n",
    "}\n",
    "\n",
    "\n",
    "def get_ossinsight(question):\n",
    "    \"\"\"\n",
    "    [Mock] Retrieve the top 10 developers with the most followers on GitHub.\n",
    "    \"\"\"\n",
    "    report_components = [\n",
    "        f\"Question: {question}\",\n",
    "        \"SQL: SELECT `login` AS `user_login`, `followers` AS `followers` FROM `github_users` ORDER BY `followers` DESC LIMIT 10\",\n",
    "        \"\"\"Results:\n",
    "  {'followers': 166730, 'user_login': 'torvalds'}\n",
    "  {'followers': 86239, 'user_login': 'yyx990803'}\n",
    "  {'followers': 77611, 'user_login': 'gaearon'}\n",
    "  {'followers': 72668, 'user_login': 'ruanyf'}\n",
    "  {'followers': 65415, 'user_login': 'JakeWharton'}\n",
    "  {'followers': 60972, 'user_login': 'peng-zhihui'}\n",
    "  {'followers': 58172, 'user_login': 'bradtraversy'}\n",
    "  {'followers': 52143, 'user_login': 'gustavoguanabara'}\n",
    "  {'followers': 51542, 'user_login': 'sindresorhus'}\n",
    "  {'followers': 49621, 'user_login': 'tj'}\"\"\",\n",
    "    ]\n",
    "    return \"\\n\" + \"\\n\\n\".join(report_components) + \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining an OpenAI Assistant Agent in AutoGen\n",
    "\n",
    "Here, we explore how to define an OpenAI Assistant Agent within the AutoGen. This includes setting up the agent to make use of the previously defined function calls for data retrieval and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenAI client config of GPTAssistantAgent(OSS Analyst) - model: gpt-4-turbo-preview\n",
      "GPT Assistant only supports one OpenAI client. Using the first client in the list.\n",
      "No matching assistant found, creating a new assistant\n"
     ]
    }
   ],
   "source": [
    "assistant_id = os.environ.get(\"ASSISTANT_ID\", None)\n",
    "config_list = config_list_from_json(\"OAI_CONFIG_LIST\")\n",
    "llm_config = {\n",
    "    \"config_list\": config_list,\n",
    "}\n",
    "assistant_config = {\n",
    "    \"assistant_id\": assistant_id,\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": ossinsight_api_schema,\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "oss_analyst = GPTAssistantAgent(\n",
    "    name=\"OSS Analyst\",\n",
    "    instructions=(\n",
    "        \"Hello, Open Source Project Analyst. You'll conduct comprehensive evaluations of open source projects or organizations on the GitHub platform, \"\n",
    "        \"analyzing project trajectories, contributor engagements, open source trends, and other vital parameters. \"\n",
    "        \"Please carefully read the context of the conversation to identify the current analysis question or problem that needs addressing.\"\n",
    "    ),\n",
    "    llm_config=llm_config,\n",
    "    assistant_config=assistant_config,\n",
    "    verbose=True,\n",
    ")\n",
    "oss_analyst.register_function(\n",
    "    function_map={\n",
    "        \"ossinsight_data_api\": get_ossinsight,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching GitHub Insight Data using Function Call\n",
    "\n",
    "This part of the notebook demonstrates the practical application of the defined functions and the OpenAI Assistant Agent in fetching and interpreting GitHub Insight data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to OSS Analyst):\n",
      "\n",
      "Top 10 developers with the most followers\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION ossinsight_data_api...\u001b[0m\n",
      "\u001b[35m\n",
      "Input arguments: {'question': 'Top 10 developers with the most followers'}\n",
      "Output:\n",
      "\n",
      "Question: Top 10 developers with the most followers\n",
      "\n",
      "SQL: SELECT `login` AS `user_login`, `followers` AS `followers` FROM `github_users` ORDER BY `followers` DESC LIMIT 10\n",
      "\n",
      "Results:\n",
      "  {'followers': 166730, 'user_login': 'torvalds'}\n",
      "  {'followers': 86239, 'user_login': 'yyx990803'}\n",
      "  {'followers': 77611, 'user_login': 'gaearon'}\n",
      "  {'followers': 72668, 'user_login': 'ruanyf'}\n",
      "  {'followers': 65415, 'user_login': 'JakeWharton'}\n",
      "  {'followers': 60972, 'user_login': 'peng-zhihui'}\n",
      "  {'followers': 58172, 'user_login': 'bradtraversy'}\n",
      "  {'followers': 52143, 'user_login': 'gustavoguanabara'}\n",
      "  {'followers': 51542, 'user_login': 'sindresorhus'}\n",
      "  {'followers': 49621, 'user_login': 'tj'}\n",
      "\u001b[0m\n",
      "\u001b[33mOSS Analyst\u001b[0m (to user_proxy):\n",
      "\n",
      "The top 10 developers with the most followers on GitHub are:\n",
      "\n",
      "1. **Linus Torvalds** (`torvalds`) with 166,730 followers\n",
      "2. **Evan You** (`yyx990803`) with 86,239 followers\n",
      "3. **Dan Abramov** (`gaearon`) with 77,611 followers\n",
      "4. **Ruan YiFeng** (`ruanyf`) with 72,668 followers\n",
      "5. **Jake Wharton** (`JakeWharton`) with 65,415 followers\n",
      "6. **Peng Zhihui** (`peng-zhihui`) with 60,972 followers\n",
      "7. **Brad Traversy** (`bradtraversy`) with 58,172 followers\n",
      "8. **Gustavo Guanabara** (`gustavoguanabara`) with 52,143 followers\n",
      "9. **Sindre Sorhus** (`sindresorhus`) with 51,542 followers\n",
      "10. **TJ Holowaychuk** (`tj`) with 49,621 followers\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to OSS Analyst):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mOSS Analyst\u001b[0m (to user_proxy):\n",
      "\n",
      "It looks like there is no question or prompt for me to respond to. Could you please provide more details or ask a question that you would like assistance with?\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permanently deleting assistant...\n"
     ]
    }
   ],
   "source": [
    "user_proxy = UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"coding\",\n",
    "        \"use_docker\": False,\n",
    "    },  # Please set use_docker=True if docker is available to run the generated code. Using docker is safer than running the generated code directly.\n",
    "    is_termination_msg=lambda msg: \"TERMINATE\" in msg[\"content\"],\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=1,\n",
    ")\n",
    "\n",
    "user_proxy.initiate_chat(oss_analyst, message=\"Top 10 developers with the most followers\")\n",
    "oss_analyst.delete_assistant()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
